\documentclass[a4paper,oneside,reqno]{amsart}
\usepackage{pdfpages} % to include cover sheet

\input{../../../cambridge-macros.tex}

%    Set assignment information here
\newcommand{\authorname}{Feynman Liang}
\newcommand{\coursename}{MLSALT 9: Statistical Spoken Dialogue Systems}
\newcommand{\assignmentname}{Practical 1}

\begin{document}

%\includepdf[noautoscale]{MLSALT_Coversheet.pdf}

\title{\coursename\\\assignmentname}

\author{\authorname}
\date{\today}

\maketitle

\section{Focus dialogue state tracker}

\subsection{Comparing performance of baseline vs focus tracker}

We evaluate the performance of the baseline (\autoref{tab:baseline-tracker})
and focus (\autoref{tab:focus-tracker} tracker on the DSTC \textbf{dtsc2\_data}
dataset.

\begin{table}[ht!]
  \begin{tabular}{cccc}
    \toprule
                  &   Joint Goals   &    Requested    &      Method    \\
    \midrule
    Accuracy      &    0.5686546    &    0.9162437    &    0.8529820   \\
    l2            &    0.8344502    &    0.1204444    &    0.2560611   \\
    roc.v2\_ca05  &    0.0000000    &    0.6066482    &    0.0016260   \\
    \bottomrule
  \end{tabular}
  \caption{Baseline tracker performance}
  \label{tab:baseline-tracker}
\end{table}

\begin{table}[ht!]
  \begin{tabular}{cccc}
    \toprule
                  &   Joint Goals   &    Requested    &      Method    \\
    \midrule
    Accuracy      &    0.7323162    &    0.9162437    &    0.5492372   \\
    l2            &    0.4212595    &    0.1194034    &    0.7911165   \\
    roc.v2\_ca05  &    0.0000000    &    0.5623269    &    0.0000000   \\
    \bottomrule
  \end{tabular}
  \caption{Focus tracker performance}
  \label{tab:focus-tracker}
\end{table}

Notice that the focus tracker has improved performance in joint goals tracking.
This is because the focus tracker's update rule
\begin{align}
  \label{eq:focus}
  p_{c,t}(v) &= slu_{t,c}(v) + q_{c,t} p_{c,t-1}(v)
\end{align}
incorperates evidence accumulated over prior dialogue terms through the $p_{c,t-1}(v)$
term, allowing the belief state over joint goals to be estimated over the course
of the dialogue rather than solely using information from that current turn (which is
the case for the baseline tracker).

However, method tracking performance is worse in the focus tracker. This
suggests that it is better to predict the method using only information from
the previous dialogue turn (as in the baseline model) than to accumulate belief
over the entire dialogue. One explanation for this is that unlike goals, which
should remain similar across multiple turns, the method is more likely to
differ across turns.  For example, a user could give a constraint one turn
(``by constraints'' method) and then issue a ``reqalts'' next turn (``by
alternatives'' method). Since the method is more likely to change across turns,
accumulating prior beliefs of the method over turns hurts the performance.

\subsection{Implementation}

\autoref{lst:focus-goal} shows our implementation of the focus tracker for goal
tracking. This code directly implements \autoref{eq:focus} and is run inside of
a \texttt{for} loop over \texttt{slot}s.

\lstinputlisting[firstnumber=339,firstline=339,lastline=344,caption=Focus goal
tracking,label=lst:focus-goal]{
cued-python_practical/practical1_dst/scripts/baseline.py}

In \autoref{lst:focus-method}, we implement the focus tracker for method tracking.
Unlike goal tracking, which maintains a belief distribution over values for each slot,
there is only a single belief distribution over all methods so this code
is not run inside of a \texttt{for} loop.

\lstinputlisting[firstnumber=355,firstline=355,lastline=359,caption=Focus method
tracking,label=lst:focus-method]{
cued-python_practical/practical1_dst/scripts/baseline.py}

\autoref{lst:focus-req} shows our implementation of the focus tracker for
requested slot tracking.  This code runs inside a \texttt{for} loop over
\texttt{slot}s. We update the requested slot belief state by clearing the
requested probability if the slot has been informed (and hence is no longer
requested by the user) and otherwise combining the SLU estimate \texttt{p} with
the previous belief state (if it exists) weighted by \texttt{q\_c\_t = 1 - p}
(the probability that the SLU found no information about \texttt{slot} being
requested this dialogue turn).

\lstinputlisting[firstnumber=377,firstline=377,lastline=382,caption=Requested
slot tracking,label=lst:focus-req]{
cued-python_practical/practical1_dst/scripts/baseline.py}

\section{Monte carlo policy}

\subsection{Performance of MCC policy}

\begin{figure}[ht!]
  \begin{center}
    \includegraphics[scale=1.0]{Figures/mcc.pdf}
  \end{center}
  \caption{MCC Success Per Diagogue Turn}
  \label{fig:mcc}
\end{figure}

\subsection{Implementation}

\lstinputlisting[firstnumber=249,firstline=249,lastline=269,caption=MCC
policy update,label=lst:mcc]{cued-python_practical/policy/MCCPolicy.py}

\lstinputlisting[firstnumber=364,firstline=364,lastline=367,caption=MCC epsilon
greedy action
selection,label=lst:mcc-action]{cued-python_practical/policy/MCCPolicy.py}

\section{GP-SARSA policy}

\subsection{Performance of GP-SARSA}

We compare the best MCC policy against GP-SARSA in TODO.

\begin{figure}[ht!]
  \begin{center}
    \includegraphics[scale=1.0]{Figures/gp.pdf}
  \end{center}
  \caption{GP-SARSA Success Per Dialogue Turn}
  \label{fig:gp}
\end{figure}


\subsection{Implementation}

\lstinputlisting[firstnumber=597,firstline=597,lastline=609,caption=GP-SARSA
spaarsification criterion check,label=lst:gp]{cued-python_practical/policy/GPLib.py}

\end{document}
